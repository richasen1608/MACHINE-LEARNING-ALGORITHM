# -*- coding: utf-8 -*-
"""Linear_Ridge_Lasso.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zARu6EVTGgfyibTkvoutLJP5k2KNXZd8

LINEAR REGRESSION , RIDGE AND LASSO
"""

#house pricing
import sklearn.datasets
from sklearn.datasets import fetch_california_housing

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline

df=fetch_california_housing()

type(df)

df

dataset=pd.DataFrame(df.data)
dataset.colums=df.feature_namesdataset.head()

dataset['price']=df.target

dataset.head()

#dividing the dataset into independent and dependent features
X=dataset.iloc[:,:-1]#independent features
y=dataset.iloc[:,-1]#dependent features

X.head()

y.head()

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=40)

#Linear regression
from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
lin_reg=LinearRegression()
lin_reg.fit(X_train,y_train)
mse=cross_val_score(lin_reg,X_train,y_train,scoring='neg_mean_squared_error',cv=5)
print(mse)
mean_mse=np.mean(mse)
print(mean_mse)

"""RIDGE REGRESSION"""

from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
ridge=Ridge()
params={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,4,10,90,77,45,999]}
ridge_regressor=GridSearchCV(ridge,params,scoring='neg_mean_squared_error',cv=5)
ridge_regressor.fit(X_train,y_train)

print(ridge_regressor.best_params_)
print(ridge_regressor.best_score_)



"""LASSO REGRESSION"""

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV
lasso=Lasso()
params={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,4,10,45,60,76,78,999]}
lasso_regressor=GridSearchCV(lasso,params,scoring='neg_mean_squared_error',cv=5)
lasso_regressor.fit(X_train,y_train)

print(lasso_regressor.best_params_)
print(lasso_regressor.best_score_)

y_pred=lasso_regressor.predict(X_test)
from sklearn.metrics import r2_score
r2_score=r2_score(y_test,y_pred)
print(r2_score)

y_pred=ridge_regressor.predict(X_test)
from sklearn.metrics import r2_score
r2_score=r2_score(y_test,y_pred)
print(r2_score)

y_pred=lin_reg.predict(X_test)
from sklearn.metrics import r2_score
r2_score=r2_score(y_test,y_pred)
print(r2_score)



"""LOGISTIC REGRESSION"""

from sklearn.linear_model import LogisticRegression
from sklearn.datasets import load_breast_cancer
df=load_breast_cancer()
##independent features
X=pd.DataFrame(df['data'],columns=df['feature_names'])

X.head()

##dependent features
y=pd.DataFrame(df['target'],columns=['Target'])
y.head()

y['Target'].value_counts()

##train test split

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=40)

params=[{'C':[1,5,10]},{'max_iter':[100,150]}]
model1=LogisticRegression(C=100,max_iter=100)
model=GridSearchCV(model1,param_grid=params,scoring='f1',cv=5)

model.fit(X_train,y_train)

model.best_params_

model.best_score_

y_pred=model.predict(X_test)
y_pred

from sklearn.metrics import confusion_matrix,classification_report,accuracy_score
confusion_matrix(y_test,y_pred)

accuracy_score(y_test,y_pred)

print (classification_report(y_test,y_pred))

